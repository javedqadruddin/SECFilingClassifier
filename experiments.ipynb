{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Embedding, Flatten, Dropout, Convolution1D, MaxPooling1D, concatenate\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.optimizers import Adam\n",
    "import keras.preprocessing.text\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import NLP_utils\n",
    "import numpy as np\n",
    "import pickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying SEC filings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, I'm going to do a quick and dirty project to prove out feasibility of using neural networks to classify legal documents.  There's a great dataset available publicly on the SEC's website.  I wrote a scraper, which you can find here: https://github.com/javedqadruddin/EDGAR that can download large numbers of different types of SEC filings.  For this experiment, I grabbed a sample of about 4000 documents each of 10-K, 10-Q, and 8-K filings (for those interested, these are filings that all public companies must make with the SEC periodically)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'data/real'\n",
    "MAX_SEQUENCE_LENGTH = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files are really big, so it'll take forever to run a ML model on whole files, and, even if we wanted to, we'd have to find a way around the fact that they won't all fit in memory.  Instead of using whole files, we'll just grab the first 1000 words of each.  The first 1000 words should be more than enough text to be able to distinguish these types of documents from each other.  A human can certainly distinguish them within the first 1000 words.. we'll see now whether we can train a computer to do it.  This handy utility I wrote grabs the data and labels each datapoint appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(texts, labels_index, labels) = NLP_utils.get_labelled_data_from_directories(data_path, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step will be to take our samples of 1000 words from each document and turn each of them into a sequence of 1000 numbers that represent the words.  Those numbers will stand for the word and, later on, will point us to a vectorized representation of the word they stand for.  A tokenizer goes through a body of text and assigns a number to each unique 'word' it finds.  Generally, tokenizers will assign numbers to punctuation marks as well. We're using a filter here to tell it to simply ignore puctuation certain puctuation marks that we don't think are important to our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000, filters=NLP_utils.filter_not_punctuation())\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[238, 232, 229, 230, 253, 56, 256, 249, 126, 29]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "sequences[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenizer labelled every single unique word with a number, and there were several hundred thousand unique words in the corpus.  Having that many unique words to learn about, most of which only appear in the corpus only once, will increase the complexity of our model and probably make our results worse. So, we will simplify things by making every word with a number > 10000 equal to 10000. The tokenizer very helpfully assigns the numbers in the order from most common word to least common, so everything with a number over 10000 probably only appears once or a handful of times. We will just set them all to 10000 so that the number 10000 will be interpreted by the model to simply mean 'rare word here'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[238, 232, 229, 230, 253, 56, 256, 249, 126, 29]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#contstraining vocab to 10000\n",
    "for sequence in sequences:\n",
    "    sequence = [10000 for num in sequence if num > 10000]\n",
    "sequences[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure all our inputs are of the same size, we pad them, since, theoretically, some of them could have been less than 1000 words long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 12451, 12452, 12453])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data.shape[0]\n",
    "np.arange(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting train and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we break the data into training sets and validation sets. The model will only see the training set while training, so the validation set will be able to tell us how the model does on data it hasn't seen. It's important to shuffle the data when doing this because, if examples from each class are grouped together, the model will sequentially learn to always guess class 1 when it's looking at the class 1 data, then it'll re-train to guess class 2 when it gets shown only class 2 data, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (12454, 1000)\n",
      "Shape of label tensor: (12454, 3)\n"
     ]
    }
   ],
   "source": [
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "VALIDATION_SPLIT = .2\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving the training data so it can be used again without going through the whole process above\n",
    "training_vector_save_path = 'data/training_vectors/'\n",
    "pickle.dump(x_train, open( training_vector_save_path + 'x_train.pk', \"wb\" ))\n",
    "pickle.dump(y_train, open( training_vector_save_path + 'y_train.pk', \"wb\" ))\n",
    "pickle.dump(x_val, open( training_vector_save_path + 'x_val.pk', \"wb\" ))\n",
    "pickle.dump(y_val, open( training_vector_save_path + 'y_val.pk', \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = pickle.load(open(\"data/training_vectors/x_train.pk\", \"rb\" ))\n",
    "y_train = pickle.load(open(\"data/training_vectors/y_train.pk\", \"rb\" ))\n",
    "x_val = pickle.load(open(\"data/training_vectors/x_val.pk\", \"rb\" ))\n",
    "y_val = pickle.load(open(\"data/training_vectors/y_val.pk\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Simple "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model is just an embedding layer with a single hidden dense layer. A little bit of dropout is added to protect against overfitting.  The embedding layer will learn a vectorized representation of each of the 10000 unique words we've given numbers to.  Each number will get a 32 dimensional vector to represent it.  The absolute positions of the words in the samples will be taken into account by the dense layer, along with their relative frequencies, but a dense layer will have quite a tough time learning to use small combinations of words that have meaning when they appear together in different places. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(10000, 32, input_length=MAX_SEQUENCE_LENGTH),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(3, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 32)          320000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               3200100   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 3,520,403\n",
      "Trainable params: 3,520,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9964 samples, validate on 2490 samples\n",
      "Epoch 1/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0030 - acc: 0.9986 - val_loss: 0.0124 - val_acc: 0.9948\n",
      "Epoch 2/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0032 - acc: 0.9986 - val_loss: 0.0119 - val_acc: 0.9948\n",
      "Epoch 3/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0119 - val_acc: 0.9956\n",
      "Epoch 4/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0027 - acc: 0.9989 - val_loss: 0.0122 - val_acc: 0.9948\n",
      "Epoch 5/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0023 - acc: 0.9988 - val_loss: 0.0139 - val_acc: 0.9948\n",
      "Epoch 6/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0022 - acc: 0.9990 - val_loss: 0.0114 - val_acc: 0.9952\n",
      "Epoch 7/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0022 - acc: 0.9991 - val_loss: 0.0116 - val_acc: 0.9952\n",
      "Epoch 8/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0022 - acc: 0.9989 - val_loss: 0.0116 - val_acc: 0.9952\n",
      "Epoch 9/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0019 - acc: 0.9992 - val_loss: 0.0112 - val_acc: 0.9960\n",
      "Epoch 10/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0020 - acc: 0.9992 - val_loss: 0.0116 - val_acc: 0.9952\n",
      "Epoch 11/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0018 - acc: 0.9992 - val_loss: 0.0114 - val_acc: 0.9956\n",
      "Epoch 12/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0017 - acc: 0.9992 - val_loss: 0.0119 - val_acc: 0.9952\n",
      "Epoch 13/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0017 - acc: 0.9992 - val_loss: 0.0113 - val_acc: 0.9960\n",
      "Epoch 14/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0017 - acc: 0.9992 - val_loss: 0.0113 - val_acc: 0.9956\n",
      "Epoch 15/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0017 - acc: 0.9992 - val_loss: 0.0111 - val_acc: 0.9960\n",
      "Epoch 16/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0017 - acc: 0.9992 - val_loss: 0.0114 - val_acc: 0.9960\n",
      "Epoch 17/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0016 - acc: 0.9992 - val_loss: 0.0119 - val_acc: 0.9952\n",
      "Epoch 18/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0018 - acc: 0.9992 - val_loss: 0.0115 - val_acc: 0.9956\n",
      "Epoch 19/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0017 - acc: 0.9992 - val_loss: 0.0110 - val_acc: 0.9960\n",
      "Epoch 20/20\n",
      "9964/9964 [==============================] - 0s - loss: 0.0017 - acc: 0.9992 - val_loss: 0.0113 - val_acc: 0.9960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ae04c0048>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=20, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for the simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it looks like our job is going to be pretty easy!  The simplest possible model we could use is already within four-tenths of a percent of perfect on the validation set.  It probably works well enough already and took less than 20 seconds to train. That's pretty awesome, but let's see if we can do better.  We'll save the weights on this network so we can use it again later if we want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = 'weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save_weights(model_path + '1_dense_20_epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll try a slightly more complex model. This model has 3 different size convolutions we'll apply to the raw input. Note, we are not stacking the convolutions on top of each other. We are instead applying 3 different convolutions with different sized filters to the raw input from the input layer. Essentially what this is doing is looking for useful bigrams, trigrams and 4-grams and then just serving them all up side-by-side to a later dense layer that'll make sense out of them. \n",
    "\n",
    "Acutally, that's a bit of a simplification--each conv finds a kind of bigram concept, trigram concept or 4-gram concept. The filter size 2 one isn't looking for specific bigrams, but rather each of its convs look for two-word sets that have a similar encoded meaning, kind of like 'good day' and 'good morrow'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 10000, 32)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)                (None, 10000, 64)     4160        input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)                (None, 10000, 64)     6208        input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)                (None, 10000, 64)     8256        input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)   (None, 5000, 64)      0           conv1d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)   (None, 5000, 64)      0           conv1d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)   (None, 5000, 64)      0           conv1d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 320000)        0           max_pooling1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 320000)        0           max_pooling1d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)              (None, 320000)        0           max_pooling1d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 960000)        0           flatten_5[0][0]                  \n",
      "                                                                   flatten_6[0][0]                  \n",
      "                                                                   flatten_7[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 18,624\n",
      "Trainable params: 18,624\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "graph_in = Input ((10000, 32))\n",
    "convs = [ ] \n",
    "for fsz in range (2, 5): \n",
    "    x = Convolution1D(64, fsz, padding='same', activation=\"relu\")(graph_in)\n",
    "    x = MaxPooling1D()(x) \n",
    "    x = Flatten()(x) \n",
    "    convs.append(x)\n",
    "out = Concatenate()(convs) \n",
    "graph = Model(graph_in, out) \n",
    "graph.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "three_convs_model = Sequential ([\n",
    "    Embedding(10000, 32, input_length=MAX_SEQUENCE_LENGTH),\n",
    "    Dropout (0.2),\n",
    "    graph,\n",
    "    Dropout (0.2),\n",
    "    Dense (100, activation=\"relu\"),\n",
    "    Dropout (0.2),\n",
    "    Dense (3, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 1000, 32)          320000    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1000, 32)          0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              multiple                  18624     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 96000)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               9600100   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 9,939,027\n",
      "Trainable params: 9,939,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "three_convs_model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "three_convs_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9964 samples, validate on 2490 samples\n",
      "Epoch 1/10\n",
      "9964/9964 [==============================] - 6s - loss: 0.1405 - acc: 0.9421 - val_loss: 0.0222 - val_acc: 0.9924\n",
      "Epoch 2/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0082 - acc: 0.9972 - val_loss: 0.0086 - val_acc: 0.9960\n",
      "Epoch 3/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0047 - acc: 0.9984 - val_loss: 0.0098 - val_acc: 0.9964\n",
      "Epoch 4/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0029 - acc: 0.9988 - val_loss: 0.0086 - val_acc: 0.9976\n",
      "Epoch 5/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0022 - acc: 0.9991 - val_loss: 0.0080 - val_acc: 0.9972\n",
      "Epoch 6/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0020 - acc: 0.9991 - val_loss: 0.0082 - val_acc: 0.9972\n",
      "Epoch 7/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0021 - acc: 0.9991 - val_loss: 0.0072 - val_acc: 0.9980\n",
      "Epoch 8/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0019 - acc: 0.9992 - val_loss: 0.0060 - val_acc: 0.9980\n",
      "Epoch 9/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0018 - acc: 0.9992 - val_loss: 0.0070 - val_acc: 0.9980\n",
      "Epoch 10/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0018 - acc: 0.9992 - val_loss: 0.0076 - val_acc: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2adddb5ef0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_convs_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like a more complex model does help somewhat. It's beating the 1-dense-layer model already after only 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "three_convs_model.save_weights(model_path + '3_convs_10_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "three_convs_model.optimizer.lr=0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further training on this more complex model doesn't seem to improve things much.. it seems to have converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9964 samples, validate on 2490 samples\n",
      "Epoch 1/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0018 - acc: 0.9992 - val_loss: 0.0064 - val_acc: 0.9980\n",
      "Epoch 2/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0018 - acc: 0.9992 - val_loss: 0.0064 - val_acc: 0.9980\n",
      "Epoch 3/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0017 - acc: 0.9992 - val_loss: 0.0074 - val_acc: 0.9980\n",
      "Epoch 4/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0016 - acc: 0.9992 - val_loss: 0.0074 - val_acc: 0.9980\n",
      "Epoch 5/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0018 - acc: 0.9992 - val_loss: 0.0072 - val_acc: 0.9980\n",
      "Epoch 6/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0017 - acc: 0.9992 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "Epoch 7/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0181 - val_acc: 0.9968\n",
      "Epoch 8/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0068 - acc: 0.9980 - val_loss: 0.0087 - val_acc: 0.9980\n",
      "Epoch 9/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0049 - acc: 0.9980 - val_loss: 0.0030 - val_acc: 0.9984\n",
      "Epoch 10/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0049 - val_acc: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2adc0d13c8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_convs_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of the 3-conv model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training results beat the simpler model by 0.3%. So, even with very little room for improvement, the more complex model does improve results. It was able to correctly classify roughly half of the last few difficult examples that the simpler model couldn't get, and it was able to do it after fewer epochs of training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can do even better. Next I'll create a model similar to the conv model except that the input tensor gets fed to the dense layer along with the conv layers.  The prior model might have lost some important details about individual words by getting all of its information filtered through the convs.  This approach should avoid losing that single-word-level detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_11 (InputLayer)            (None, 10000, 32)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)               (None, 10000, 64)     4160        input_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)               (None, 10000, 64)     6208        input_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)               (None, 10000, 64)     8256        input_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D)  (None, 5000, 64)      0           conv1d_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D)  (None, 5000, 64)      0           conv1d_32[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D)  (None, 5000, 64)      0           conv1d_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)             (None, 320000)        0           max_pooling1d_31[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)             (None, 320000)        0           max_pooling1d_32[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)             (None, 320000)        0           max_pooling1d_33[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)     (None, 960000)        0           flatten_32[0][0]                 \n",
      "                                                                   flatten_33[0][0]                 \n",
      "                                                                   flatten_34[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)             (None, 320000)        0           input_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)     (None, 1280000)       0           concatenate_16[0][0]             \n",
      "                                                                   flatten_35[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 18,624\n",
      "Trainable params: 18,624\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input ((10000, 32))\n",
    "convs = [] \n",
    "for num in range (2, 5): \n",
    "    x = Convolution1D(64, num, padding='same', activation=\"relu\")(input_tensor)\n",
    "    x = MaxPooling1D()(x) \n",
    "    x = Flatten()(x) \n",
    "    convs.append(x)\n",
    "\n",
    "conv_out = Concatenate()(convs)\n",
    "shortcut = Flatten()(input_tensor)\n",
    "full_out = Concatenate()([conv_out, shortcut])\n",
    "\n",
    "graph = Model(input_tensor, full_out) \n",
    "graph.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "three_convs_w_shortcut_model = Sequential ([\n",
    "    Embedding(10000, 32, input_length=MAX_SEQUENCE_LENGTH),\n",
    "    Dropout (0.2),\n",
    "    graph,\n",
    "    Dropout (0.2),\n",
    "    Dense (100, activation=\"relu\"),\n",
    "    Dropout (0.2),\n",
    "    Dense (3, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 1000, 32)          320000    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1000, 32)          0         \n",
      "_________________________________________________________________\n",
      "model_3 (Model)              multiple                  18624     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               12800100  \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 13,139,027\n",
      "Trainable params: 13,139,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "three_convs_w_shortcut_model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "three_convs_w_shortcut_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9964 samples, validate on 2490 samples\n",
      "Epoch 1/10\n",
      "9964/9964 [==============================] - 6s - loss: 0.1188 - acc: 0.9550 - val_loss: 0.0102 - val_acc: 0.9964\n",
      "Epoch 2/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0051 - acc: 0.9982 - val_loss: 0.0082 - val_acc: 0.9972\n",
      "Epoch 3/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0037 - acc: 0.9983 - val_loss: 0.0066 - val_acc: 0.9964\n",
      "Epoch 4/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0025 - acc: 0.9986 - val_loss: 0.0058 - val_acc: 0.9976\n",
      "Epoch 5/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0024 - acc: 0.9990 - val_loss: 0.0065 - val_acc: 0.9968\n",
      "Epoch 6/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0023 - acc: 0.9986 - val_loss: 0.0050 - val_acc: 0.9980\n",
      "Epoch 7/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0019 - acc: 0.9992 - val_loss: 0.0054 - val_acc: 0.9976\n",
      "Epoch 8/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0018 - acc: 0.9992 - val_loss: 0.0049 - val_acc: 0.9976\n",
      "Epoch 9/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0018 - acc: 0.9992 - val_loss: 0.0061 - val_acc: 0.9976\n",
      "Epoch 10/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0019 - acc: 0.9992 - val_loss: 0.0064 - val_acc: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ade324c50>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_convs_w_shortcut_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No improvement over the conv model, maybe slightly worse... let's try another 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9964 samples, validate on 2490 samples\n",
      "Epoch 1/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0026 - acc: 0.9989 - val_loss: 0.0042 - val_acc: 0.9984\n",
      "Epoch 2/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0018 - acc: 0.9992 - val_loss: 0.0044 - val_acc: 0.9980\n",
      "Epoch 3/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0018 - acc: 0.9992 - val_loss: 0.0052 - val_acc: 0.9972\n",
      "Epoch 4/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0017 - acc: 0.9992 - val_loss: 0.0044 - val_acc: 0.9972\n",
      "Epoch 5/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0018 - acc: 0.9992 - val_loss: 0.0041 - val_acc: 0.9984\n",
      "Epoch 6/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0017 - acc: 0.9992 - val_loss: 0.0045 - val_acc: 0.9972\n",
      "Epoch 7/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0016 - acc: 0.9992 - val_loss: 0.0041 - val_acc: 0.9980\n",
      "Epoch 8/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0017 - acc: 0.9992 - val_loss: 0.0036 - val_acc: 0.9980\n",
      "Epoch 9/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0017 - acc: 0.9992 - val_loss: 0.0040 - val_acc: 0.9976\n",
      "Epoch 10/10\n",
      "9964/9964 [==============================] - 5s - loss: 0.0017 - acc: 0.9992 - val_loss: 0.0037 - val_acc: 0.9984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2a84442dd8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_convs_w_shortcut_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of the 3-conv-with-shortcut model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It that feeding the input layer directly to the dense layer along with the output of the conv layers doesn't really improve things.  Interesting.  It would be cool to see if this shortcut idea works better on other datasets--perhaps ones where we aren't already doing so well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What else can we try to make it better?  We're reducing the number of parameters quite precipitously at the end by going straight to a 100 neuron dense layer. Perhaps a bigger dense layer first, then 100, then 3 will work better. Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_12 (InputLayer)            (None, 10000, 32)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)               (None, 10000, 64)     4160        input_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)               (None, 10000, 64)     6208        input_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)               (None, 10000, 64)     8256        input_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D)  (None, 5000, 64)      0           conv1d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D)  (None, 5000, 64)      0           conv1d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D)  (None, 5000, 64)      0           conv1d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)             (None, 320000)        0           max_pooling1d_34[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)             (None, 320000)        0           max_pooling1d_35[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)             (None, 320000)        0           max_pooling1d_36[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)     (None, 960000)        0           flatten_36[0][0]                 \n",
      "                                                                   flatten_37[0][0]                 \n",
      "                                                                   flatten_38[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)             (None, 320000)        0           input_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)     (None, 1280000)       0           concatenate_18[0][0]             \n",
      "                                                                   flatten_39[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 18,624\n",
      "Trainable params: 18,624\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input ((10000, 32))\n",
    "convs = [] \n",
    "for num in range (2, 5): \n",
    "    x = Convolution1D(64, num, padding='same', activation=\"relu\")(input_tensor)\n",
    "    x = MaxPooling1D()(x) \n",
    "    x = Flatten()(x) \n",
    "    convs.append(x)\n",
    "\n",
    "conv_out = Concatenate()(convs)\n",
    "shortcut = Flatten()(input_tensor)\n",
    "full_out = Concatenate()([conv_out, shortcut])\n",
    "\n",
    "graph_2 = Model(input_tensor, full_out) \n",
    "graph_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "three_convs_w_shortcut_model_2_dense = Sequential ([\n",
    "    Embedding(10000, 32, input_length=MAX_SEQUENCE_LENGTH),\n",
    "    Dropout (0.2),\n",
    "    graph_2,\n",
    "    Dropout (0.2),\n",
    "    Dense (200, activation=\"relu\"),\n",
    "    Dropout (0.2),\n",
    "    Dense (100, activation=\"relu\"),\n",
    "    Dropout (0.2),\n",
    "    Dense (3, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 1000, 32)          320000    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 1000, 32)          0         \n",
      "_________________________________________________________________\n",
      "model_4 (Model)              multiple                  18624     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 200)               25600200  \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 25,959,227\n",
      "Trainable params: 25,959,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "three_convs_w_shortcut_model_2_dense.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "three_convs_w_shortcut_model_2_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9964 samples, validate on 2490 samples\n",
      "Epoch 1/10\n",
      "9964/9964 [==============================] - 7s - loss: 0.0060 - acc: 0.9978 - val_loss: 0.0143 - val_acc: 0.9940\n",
      "Epoch 2/10\n",
      "9964/9964 [==============================] - 7s - loss: 0.0030 - acc: 0.9986 - val_loss: 0.0077 - val_acc: 0.9972\n",
      "Epoch 3/10\n",
      "9964/9964 [==============================] - 7s - loss: 0.0025 - acc: 0.9986 - val_loss: 0.0060 - val_acc: 0.9964\n",
      "Epoch 4/10\n",
      "9964/9964 [==============================] - 7s - loss: 0.0033 - acc: 0.9986 - val_loss: 0.0090 - val_acc: 0.9964\n",
      "Epoch 5/10\n",
      "9964/9964 [==============================] - 7s - loss: 0.0056 - acc: 0.9975 - val_loss: 0.0072 - val_acc: 0.9980\n",
      "Epoch 6/10\n",
      "9964/9964 [==============================] - 7s - loss: 0.0030 - acc: 0.9990 - val_loss: 0.0064 - val_acc: 0.9976\n",
      "Epoch 7/10\n",
      "9964/9964 [==============================] - 7s - loss: 0.0019 - acc: 0.9993 - val_loss: 0.0052 - val_acc: 0.9976\n",
      "Epoch 8/10\n",
      "9964/9964 [==============================] - 7s - loss: 0.0017 - acc: 0.9990 - val_loss: 0.0052 - val_acc: 0.9976\n",
      "Epoch 9/10\n",
      "9964/9964 [==============================] - 7s - loss: 0.0019 - acc: 0.9989 - val_loss: 0.0040 - val_acc: 0.9980\n",
      "Epoch 10/10\n",
      "9964/9964 [==============================] - 7s - loss: 0.0018 - acc: 0.9992 - val_loss: 0.0050 - val_acc: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2a7d214eb8>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_convs_w_shortcut_model_2_dense.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like that didn't really work. The same or possibly worse performance.  :-/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pre-trained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People with access to a helluva lot more data than me, and racks upon racks of GPUs have already trained word vectors on various corpora of text. The text they've trained on are in general domains, rather than our specific problem, but those embeddings contain excellent information on the relationships between Enlgish words.  I'm going to try something here that I haven't seen or tried before: I'll use the pre-trained embeddings in addition to our own embeddings.  This way, we should get the benefit of the pre-trained embeddings' information about what a word means from a huge training set, while also getting the nuance of what a word means in the context of the problem we're trying to solve.  Let's see if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove/glove.6B.50d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "truncated_word_index = {key: value for key, value in word_index.items() if value < 10000}\n",
    "print(len(truncated_word_index))\n",
    "glove_embedding_dimension = 50\n",
    "embedding_matrix = np.zeros((len(truncated_word_index) + 1, glove_embedding_dimension))\n",
    "for word, i in truncated_word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glove_embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            glove_embedding_dimension,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 1000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_embedding (Embedding)       (None, 1000, 32)      320000      main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "glove_embedding (Embedding)      (None, 1000, 50)      500000      main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 1000, 32)      0           main_embedding[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)             (None, 1000, 50)      0           glove_embedding[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)               (None, 1000, 64)      4160        dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)               (None, 1000, 64)      6208        dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)               (None, 1000, 64)      8256        dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)               (None, 1000, 64)      6464        dropout_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)               (None, 1000, 64)      9664        dropout_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)               (None, 1000, 64)      12864       dropout_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D)  (None, 500, 64)       0           conv1d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D)  (None, 500, 64)       0           conv1d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling1D)  (None, 500, 64)       0           conv1d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D)  (None, 500, 64)       0           conv1d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D)  (None, 500, 64)       0           conv1d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D)  (None, 500, 64)       0           conv1d_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)             (None, 32000)         0           max_pooling1d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)             (None, 32000)         0           max_pooling1d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)             (None, 32000)         0           max_pooling1d_27[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)             (None, 32000)         0           max_pooling1d_28[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)             (None, 32000)         0           max_pooling1d_29[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)             (None, 32000)         0           max_pooling1d_30[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "concatenated_convs (Concatenate) (None, 192000)        0           flatten_25[0][0]                 \n",
      "                                                                   flatten_26[0][0]                 \n",
      "                                                                   flatten_27[0][0]                 \n",
      "                                                                   flatten_28[0][0]                 \n",
      "                                                                   flatten_29[0][0]                 \n",
      "                                                                   flatten_30[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "shortcut_main_embedding (Flatten (None, 32000)         0           dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concat_main_embedding_plus_convs (None, 224000)        0           concatenated_convs[0][0]         \n",
      "                                                                   shortcut_main_embedding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)             (None, 224000)        0           concat_main_embedding_plus_convs[\n",
      "____________________________________________________________________________________________________\n",
      "dense_consolidator (Dense)       (None, 100)           22400100    dropout_19[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)             (None, 100)           0           dense_consolidator[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "final_output (Dense)             (None, 3)             303         dropout_20[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 23,268,019\n",
      "Trainable params: 22,768,019\n",
      "Non-trainable params: 500,000\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(1000,), dtype='int32', name='main_input')\n",
    "\n",
    "embedding_layer = Embedding(10000, 32, input_length=1000, name='main_embedding')(input_tensor)\n",
    "embedding_layer = Dropout(0.2)(embedding_layer)\n",
    "\n",
    "glove_embedding_layer = Embedding(10000, 50, input_length=1000, name='glove_embedding', weights=[embedding_matrix], trainable=False)(input_tensor)\n",
    "glove_embedding_layer = Dropout(0.2)(glove_embedding_layer)\n",
    "\n",
    "convs = [] \n",
    "for num in range (2, 5): \n",
    "    x = Convolution1D(64, num, padding='same', activation=\"relu\")(embedding_layer)\n",
    "    x = MaxPooling1D()(x) \n",
    "    x = Flatten()(x) \n",
    "    convs.append(x)\n",
    "\n",
    "for num in range (2, 5): \n",
    "    x = Convolution1D(64, num, padding='same', activation=\"relu\")(glove_embedding_layer)\n",
    "    x = MaxPooling1D()(x) \n",
    "    x = Flatten()(x) \n",
    "    convs.append(x)\n",
    "\n",
    "conv_out = Concatenate(name='concatenated_convs')(convs)\n",
    "shortcut = Flatten(name='shortcut_main_embedding')(embedding_layer)\n",
    "dense_in = Concatenate(name='concat_main_embedding_plus_convs')([conv_out, shortcut])\n",
    "\n",
    "nex = Dropout(0.2)(dense_in)\n",
    "nex = Dense(100, activation=\"relu\", name='dense_consolidator')(nex)\n",
    "nex = Dropout(0.2)(nex)\n",
    "full_out = Dense (3, activation='softmax', name='final_output')(nex)\n",
    "\n",
    "shortcut_glove_model = Model(input_tensor, full_out) \n",
    "shortcut_glove_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shortcut_glove_model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9964 samples, validate on 2490 samples\n",
      "Epoch 1/1\n",
      "9964/9964 [==============================] - 10s - loss: 0.1660 - acc: 0.9442 - val_loss: 0.0121 - val_acc: 0.9952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce65bc3f98>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortcut_glove_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=1, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9964 samples, validate on 2490 samples\n",
      "Epoch 1/10\n",
      "9964/9964 [==============================] - 10s - loss: 0.0064 - acc: 0.9978 - val_loss: 0.0084 - val_acc: 0.9964\n",
      "Epoch 2/10\n",
      "9964/9964 [==============================] - 10s - loss: 0.0040 - acc: 0.9986 - val_loss: 0.0053 - val_acc: 0.9980\n",
      "Epoch 3/10\n",
      "9964/9964 [==============================] - 10s - loss: 0.0024 - acc: 0.9988 - val_loss: 0.0049 - val_acc: 0.9984\n",
      "Epoch 4/10\n",
      "9964/9964 [==============================] - 10s - loss: 0.0021 - acc: 0.9989 - val_loss: 0.0054 - val_acc: 0.9976\n",
      "Epoch 5/10\n",
      "9964/9964 [==============================] - 10s - loss: 0.0021 - acc: 0.9989 - val_loss: 0.0050 - val_acc: 0.9980\n",
      "Epoch 6/10\n",
      "9964/9964 [==============================] - 10s - loss: 0.0021 - acc: 0.9989 - val_loss: 0.0053 - val_acc: 0.9988\n",
      "Epoch 7/10\n",
      "9964/9964 [==============================] - 10s - loss: 0.0020 - acc: 0.9990 - val_loss: 0.0055 - val_acc: 0.9984\n",
      "Epoch 8/10\n",
      "9964/9964 [==============================] - 10s - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0055 - val_acc: 0.9984\n",
      "Epoch 9/10\n",
      "9964/9964 [==============================] - 10s - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0051 - val_acc: 0.9984\n",
      "Epoch 10/10\n",
      "9964/9964 [==============================] - 11s - loss: 0.0020 - acc: 0.9992 - val_loss: 0.0058 - val_acc: 0.9984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce659ef978>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortcut_glove_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool!  Not much better than before, but probably the best consistent performance so far. Adding in the pre-trained word vectors seems to have had at least a small payoff. Potential places to go from here are to try increasing the dropout, because it looks like we could be overfitting slightly. But let's save weights and try another 10 epochs and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shortcut_glove_model.save_weights(model_path + 'shortcut_glove_10_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9964 samples, validate on 2490 samples\n",
      "Epoch 1/10\n",
      "9964/9964 [==============================] - 10s - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0070 - val_acc: 0.9980\n",
      "Epoch 2/10\n",
      "9964/9964 [==============================] - 10s - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "Epoch 3/10\n",
      "9964/9964 [==============================] - 10s - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0048 - val_acc: 0.9984\n",
      "Epoch 4/10\n",
      "9964/9964 [==============================] - 10s - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0052 - val_acc: 0.9984\n",
      "Epoch 5/10\n",
      "9964/9964 [==============================] - 10s - loss: 0.0018 - acc: 0.9991 - val_loss: 0.0058 - val_acc: 0.9984\n",
      "Epoch 6/10\n",
      "9964/9964 [==============================] - 10s - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0053 - val_acc: 0.9984\n",
      "Epoch 7/10\n",
      "9964/9964 [==============================] - 10s - loss: 0.0018 - acc: 0.9991 - val_loss: 0.0054 - val_acc: 0.9984\n",
      "Epoch 8/10\n",
      "9964/9964 [==============================] - 10s - loss: 0.0020 - acc: 0.9991 - val_loss: 0.0051 - val_acc: 0.9984\n",
      "Epoch 9/10\n",
      "9964/9964 [==============================] - 11s - loss: 0.0123 - acc: 0.9966 - val_loss: 0.0052 - val_acc: 0.9976\n",
      "Epoch 10/10\n",
      "9964/9964 [==============================] - 11s - loss: 0.0025 - acc: 0.9987 - val_loss: 0.0065 - val_acc: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce656f71d0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortcut_glove_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! So not a whole ton of difference, but this approach does seem to consistently edge out the other ones we tried.  Cool!  Time to save weights and call it a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shortcut_glove_model.save_weights(model_path + 'shortcut_glove_20_epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It seems that classifying SEC filings is really easy with neural networks.  None of these approaches is particularly complex or difficult to implement, and we achieved a result that gets within two-tenths of a percent of perfect on the validation set.  That is pretty damn good.  So, I'd say this proof-of-concept is a success: it's probably quite easy to use deep learning to classify contracts, filings and other similar legal documents. Yay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
