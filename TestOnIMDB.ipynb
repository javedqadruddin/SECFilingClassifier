{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.utils import get_file\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Input, Dense, Embedding, Flatten, Dropout, Convolution1D, MaxPooling1D, concatenate\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4822"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = imdb.get_word_index()\n",
    "idx['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx2word = {v: k for k, v in idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'and', 'a', 'of', 'to']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idx = sorted(idx, key=idx.get)\n",
    "sorted_idx[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grab the imdb dataset\n",
    "path = get_file('imdb_full.pkl',\n",
    "                origin='https://s3.amazonaws.com/text-datasets/imdb_full.pkl',\n",
    "                md5_hash='d091312047c43cf9e4e38fef92437263')\n",
    "f = open(path, 'rb')\n",
    "(x_train, labels_train), (x_test, labels_test) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test to see if download worked--should be 25000\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'23022, 309, 6, 3, 1069, 209, 9, 2175, 30, 1, 169, 55, 14, 46, 82, 5869, 41, 393, 110, 138, 14, 5359, 58, 4477, 150, 8, 1, 5032, 5948, 482, 69, 5, 261, 12, 23022, 73935, 2003, 6, 73, 2436, 5, 632, 71, 6, 5359, 1, 25279, 5, 2004, 10471, 1, 5941, 1534, 34, 67, 64, 205, 140, 65, 1232, 63526, 21145, 1, 49265, 4, 1, 223, 901, 29, 3024, 69, 4, 1, 5863, 10, 694, 2, 65, 1534, 51, 10, 216, 1, 387, 8, 60, 3, 1472, 3724, 802, 5, 3521, 177, 1, 393, 10, 1238, 14030, 30, 309, 3, 353, 344, 2989, 143, 130, 5, 7804, 28, 4, 126, 5359, 1472, 2375, 5, 23022, 309, 10, 532, 12, 108, 1470, 4, 58, 556, 101, 12, 23022, 309, 6, 227, 4187, 48, 3, 2237, 12, 9, 215'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test to see if entries in imdb dataset are as they should be--should be a list of numbers\n",
    "', '.join(map(str, x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test to see idx2word is working--should be 'bromwell'\n",
    "idx2word[23022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell high's satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers' pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled at high a classic line inspector i'm here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isn't\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#more check if idx2word is working--should show a whole review\n",
    "' '.join([idx2word[o] for o in x_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure training labels are there 1 is for good review, 0 for negative\n",
    "labels_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "#replaces the rare words\n",
    "trn = [np.array([i if i<vocab_size-1 else vocab_size-1 for i in s]) for s in x_train]\n",
    "test = [np.array([i if i<vocab_size-1 else vocab_size-1 for i in s]) for s in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_len = 500\n",
    "trn = sequence.pad_sequences(trn, maxlen=seq_len, value=0)\n",
    "test = sequence.pad_sequences(test, maxlen=seq_len, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test to make sure training data is right shape, should be 25000,500\n",
    "trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 500)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_embedding (Embedding)       (None, 500, 50)       250000      main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 500, 50)       0           main_embedding[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)                (None, 500, 64)       6464        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)                (None, 500, 64)       9664        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)                (None, 500, 64)       12864       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)   (None, 250, 64)       0           conv1d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)   (None, 250, 64)       0           conv1d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)   (None, 250, 64)       0           conv1d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 16000)         0           max_pooling1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 16000)         0           max_pooling1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 16000)         0           max_pooling1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "concatenated_convs (Concatenate) (None, 48000)         0           flatten_1[0][0]                  \n",
      "                                                                   flatten_2[0][0]                  \n",
      "                                                                   flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "shortcut_main_embedding (Flatten (None, 25000)         0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concat_main_embedding_plus_convs (None, 73000)         0           concatenated_convs[0][0]         \n",
      "                                                                   shortcut_main_embedding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 73000)         0           concat_main_embedding_plus_convs[\n",
      "____________________________________________________________________________________________________\n",
      "dense_consolidator (Dense)       (None, 100)           7300100     dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 100)           0           dense_consolidator[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "final_output (Dense)             (None, 1)             101         dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 7,579,193\n",
      "Trainable params: 7,579,193\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#first model with our own 50 dimensional word embeddings\n",
    "input_tensor = Input(shape=(seq_len,), dtype='int32', name='main_input')\n",
    "\n",
    "embedding_layer = Embedding(5000, 50, input_length=seq_len, name='main_embedding')(input_tensor)\n",
    "embedding_layer = Dropout(0.2)(embedding_layer)\n",
    "\n",
    "convs = [] \n",
    "for num in range (2, 5): \n",
    "    x = Convolution1D(64, num, padding='same', activation=\"relu\")(embedding_layer)\n",
    "    x = MaxPooling1D()(x) \n",
    "    x = Flatten()(x) \n",
    "    convs.append(x)\n",
    "\n",
    "conv_out = Concatenate(name='concatenated_convs')(convs)\n",
    "shortcut = Flatten(name='shortcut_main_embedding')(embedding_layer)\n",
    "dense_in = Concatenate(name='concat_main_embedding_plus_convs')([conv_out, shortcut])\n",
    "\n",
    "nex = Dropout(0.2)(dense_in)\n",
    "nex = Dense(100, activation=\"relu\", name='dense_consolidator')(nex)\n",
    "nex = Dropout(0.2)(nex)\n",
    "full_out = Dense (1, activation='sigmoid', name='final_output')(nex)\n",
    "\n",
    "local_embedding_only_50_model = Model(input_tensor, full_out) \n",
    "local_embedding_only_50_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local_embedding_only_50_model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 126s - loss: 0.4030 - acc: 0.7969 - val_loss: 0.2761 - val_acc: 0.8831\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 10s - loss: 0.1870 - acc: 0.9303 - val_loss: 0.2848 - val_acc: 0.8834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b7ef37a58>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_embedding_only_50_model.fit(trn, labels_train, validation_data=(test, labels_test), epochs=2, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/8\n",
      "25000/25000 [==============================] - 10s - loss: 0.0969 - acc: 0.9662 - val_loss: 0.3431 - val_acc: 0.8809\n",
      "Epoch 2/8\n",
      "25000/25000 [==============================] - 10s - loss: 0.0448 - acc: 0.9851 - val_loss: 0.4100 - val_acc: 0.8784\n",
      "Epoch 3/8\n",
      "25000/25000 [==============================] - 10s - loss: 0.0282 - acc: 0.9902 - val_loss: 0.4540 - val_acc: 0.8776\n",
      "Epoch 4/8\n",
      "25000/25000 [==============================] - 10s - loss: 0.0255 - acc: 0.9908 - val_loss: 0.4876 - val_acc: 0.8749\n",
      "Epoch 5/8\n",
      "25000/25000 [==============================] - 10s - loss: 0.0192 - acc: 0.9929 - val_loss: 0.5676 - val_acc: 0.8756\n",
      "Epoch 6/8\n",
      "25000/25000 [==============================] - 10s - loss: 0.0209 - acc: 0.9926 - val_loss: 0.6092 - val_acc: 0.8737\n",
      "Epoch 7/8\n",
      "25000/25000 [==============================] - 10s - loss: 0.0174 - acc: 0.9942 - val_loss: 0.5908 - val_acc: 0.8733\n",
      "Epoch 8/8\n",
      "25000/25000 [==============================] - 10s - loss: 0.0158 - acc: 0.9948 - val_loss: 0.7102 - val_acc: 0.8658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b78f75198>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_embedding_only_50_model.fit(trn, labels_train, validation_data=(test, labels_test), epochs=8, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 500)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_embedding (Embedding)       (None, 500, 100)      500000      main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 500, 100)      0           main_embedding[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)                (None, 500, 64)       12864       dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)                (None, 500, 64)       19264       dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)                (None, 500, 64)       25664       dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)   (None, 250, 64)       0           conv1d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)   (None, 250, 64)       0           conv1d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)   (None, 250, 64)       0           conv1d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 16000)         0           max_pooling1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 16000)         0           max_pooling1d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 16000)         0           max_pooling1d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "concatenated_convs (Concatenate) (None, 48000)         0           flatten_4[0][0]                  \n",
      "                                                                   flatten_5[0][0]                  \n",
      "                                                                   flatten_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "shortcut_main_embedding (Flatten (None, 50000)         0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concat_main_embedding_plus_convs (None, 98000)         0           concatenated_convs[0][0]         \n",
      "                                                                   shortcut_main_embedding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 98000)         0           concat_main_embedding_plus_convs[\n",
      "____________________________________________________________________________________________________\n",
      "dense_consolidator (Dense)       (None, 100)           9800100     dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 100)           0           dense_consolidator[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "final_output (Dense)             (None, 1)             101         dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 10,357,993\n",
      "Trainable params: 10,357,993\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#second model with our own 100 dimensional word embeddings\n",
    "input_tensor = Input(shape=(seq_len,), dtype='int32', name='main_input')\n",
    "\n",
    "embedding_layer = Embedding(5000, 100, input_length=seq_len, name='main_embedding')(input_tensor)\n",
    "embedding_layer = Dropout(0.2)(embedding_layer)\n",
    "\n",
    "convs = [] \n",
    "for num in range (2, 5): \n",
    "    x = Convolution1D(64, num, padding='same', activation=\"relu\")(embedding_layer)\n",
    "    x = MaxPooling1D()(x) \n",
    "    x = Flatten()(x) \n",
    "    convs.append(x)\n",
    "\n",
    "conv_out = Concatenate(name='concatenated_convs')(convs)\n",
    "shortcut = Flatten(name='shortcut_main_embedding')(embedding_layer)\n",
    "dense_in = Concatenate(name='concat_main_embedding_plus_convs')([conv_out, shortcut])\n",
    "\n",
    "nex = Dropout(0.2)(dense_in)\n",
    "nex = Dense(100, activation=\"relu\", name='dense_consolidator')(nex)\n",
    "nex = Dropout(0.2)(nex)\n",
    "full_out = Dense (1, activation='sigmoid', name='final_output')(nex)\n",
    "\n",
    "local_embedding_only_100_model = Model(input_tensor, full_out) \n",
    "local_embedding_only_100_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local_embedding_only_100_model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 14s - loss: 0.4215 - acc: 0.7843 - val_loss: 0.2759 - val_acc: 0.8840\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 14s - loss: 0.1769 - acc: 0.9342 - val_loss: 0.2796 - val_acc: 0.8830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b487bbfd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_embedding_only_100_model.fit(trn, labels_train, validation_data=(test, labels_test), epochs=2, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/8\n",
      "25000/25000 [==============================] - 14s - loss: 0.0645 - acc: 0.9798 - val_loss: 0.3651 - val_acc: 0.8824\n",
      "Epoch 2/8\n",
      "25000/25000 [==============================] - 14s - loss: 0.0225 - acc: 0.9929 - val_loss: 0.4424 - val_acc: 0.8787\n",
      "Epoch 3/8\n",
      "25000/25000 [==============================] - 14s - loss: 0.0157 - acc: 0.9948 - val_loss: 0.5082 - val_acc: 0.8796\n",
      "Epoch 4/8\n",
      "25000/25000 [==============================] - 14s - loss: 0.0110 - acc: 0.9970 - val_loss: 0.5616 - val_acc: 0.8765\n",
      "Epoch 5/8\n",
      "25000/25000 [==============================] - 14s - loss: 0.0189 - acc: 0.9936 - val_loss: 0.5596 - val_acc: 0.8640\n",
      "Epoch 6/8\n",
      "25000/25000 [==============================] - 14s - loss: 0.0175 - acc: 0.9938 - val_loss: 0.6106 - val_acc: 0.8656\n",
      "Epoch 7/8\n",
      "25000/25000 [==============================] - 14s - loss: 0.0141 - acc: 0.9952 - val_loss: 0.7091 - val_acc: 0.8640\n",
      "Epoch 8/8\n",
      "25000/25000 [==============================] - 14s - loss: 0.0170 - acc: 0.9944 - val_loss: 0.5703 - val_acc: 0.8774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b243806d8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_embedding_only_100_model.fit(trn, labels_train, validation_data=(test, labels_test), epochs=8, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove/glove.6B.50d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999\n"
     ]
    }
   ],
   "source": [
    "word_index = idx\n",
    "truncated_word_index = {key: value for key, value in word_index.items() if value < 5000}\n",
    "print(len(truncated_word_index))\n",
    "glove_embedding_dimension = 50\n",
    "embedding_matrix = np.zeros((len(truncated_word_index) + 1, glove_embedding_dimension))\n",
    "for word, i in truncated_word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 500)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "glove_embedding (Embedding)      (None, 500, 50)       250000      main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)               (None, 500, 64)       6464        glove_embedding[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)               (None, 500, 64)       9664        glove_embedding[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)               (None, 500, 64)       12864       glove_embedding[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D)  (None, 250, 64)       0           conv1d_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D)  (None, 250, 64)       0           conv1d_32[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D)  (None, 250, 64)       0           conv1d_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)             (None, 16000)         0           max_pooling1d_31[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)             (None, 16000)         0           max_pooling1d_32[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)             (None, 16000)         0           max_pooling1d_33[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "concatenated_convs (Concatenate) (None, 48000)         0           flatten_31[0][0]                 \n",
      "                                                                   flatten_32[0][0]                 \n",
      "                                                                   flatten_33[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "shortcut_main_embedding (Flatten (None, 25000)         0           glove_embedding[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "concat_main_embedding_plus_convs (None, 73000)         0           concatenated_convs[0][0]         \n",
      "                                                                   shortcut_main_embedding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)             (None, 73000)         0           concat_main_embedding_plus_convs[\n",
      "____________________________________________________________________________________________________\n",
      "dense_consolidator (Dense)       (None, 100)           7300100     dropout_25[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)             (None, 100)           0           dense_consolidator[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "final_output (Dense)             (None, 1)             101         dropout_26[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 7,579,193\n",
      "Trainable params: 7,329,193\n",
      "Non-trainable params: 250,000\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#third model with glove 50 dimensional word embeddings only \n",
    "input_tensor = Input(shape=(seq_len,), dtype='int32', name='main_input')\n",
    "\n",
    "glove_embedding_layer = Embedding(5000, 50, input_length=500, name='glove_embedding', weights=[embedding_matrix], trainable=False)(input_tensor)\n",
    "\n",
    "convs = [] \n",
    "for num in range (2, 5): \n",
    "    x = Convolution1D(64, num, padding='same', activation=\"relu\")(glove_embedding_layer)\n",
    "    x = MaxPooling1D()(x) \n",
    "    x = Flatten()(x) \n",
    "    convs.append(x)\n",
    "\n",
    "conv_out = Concatenate(name='concatenated_convs')(convs)\n",
    "shortcut = Flatten(name='shortcut_main_embedding')(glove_embedding_layer)\n",
    "dense_in = Concatenate(name='concat_main_embedding_plus_convs')([conv_out, shortcut])\n",
    "\n",
    "nex = Dropout(0.2)(dense_in)\n",
    "nex = Dense(100, activation=\"relu\", name='dense_consolidator')(nex)\n",
    "nex = Dropout(0.2)(nex)\n",
    "full_out = Dense (1, activation='sigmoid', name='final_output')(nex)\n",
    "\n",
    "glove_embedding_only_50_model = Model(input_tensor, full_out) \n",
    "glove_embedding_only_50_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_embedding_only_50_model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 9s - loss: 0.5714 - acc: 0.7000 - val_loss: 0.4612 - val_acc: 0.7844\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 9s - loss: 0.4038 - acc: 0.8184 - val_loss: 0.4204 - val_acc: 0.8064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0ae4be71d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embedding_only_50_model.fit(trn, labels_train, validation_data=(test, labels_test), epochs=2, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/8\n",
      "25000/25000 [==============================] - 9s - loss: 0.3172 - acc: 0.8595 - val_loss: 0.4422 - val_acc: 0.8074\n",
      "Epoch 2/8\n",
      "25000/25000 [==============================] - 9s - loss: 0.2501 - acc: 0.8934 - val_loss: 0.5008 - val_acc: 0.8018\n",
      "Epoch 3/8\n",
      "25000/25000 [==============================] - 9s - loss: 0.1976 - acc: 0.9175 - val_loss: 0.4814 - val_acc: 0.8112\n",
      "Epoch 4/8\n",
      "25000/25000 [==============================] - 9s - loss: 0.1517 - acc: 0.9368 - val_loss: 0.6004 - val_acc: 0.8141\n",
      "Epoch 5/8\n",
      "25000/25000 [==============================] - 9s - loss: 0.1266 - acc: 0.9470 - val_loss: 0.5844 - val_acc: 0.8136\n",
      "Epoch 6/8\n",
      "25000/25000 [==============================] - 9s - loss: 0.1021 - acc: 0.9566 - val_loss: 0.6650 - val_acc: 0.8134\n",
      "Epoch 7/8\n",
      "25000/25000 [==============================] - 9s - loss: 0.0944 - acc: 0.9598 - val_loss: 0.7043 - val_acc: 0.8095\n",
      "Epoch 8/8\n",
      "25000/25000 [==============================] - 9s - loss: 0.0771 - acc: 0.9675 - val_loss: 0.7610 - val_acc: 0.8092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0ae4be72b0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embedding_only_50_model.fit(trn, labels_train, validation_data=(test, labels_test), epochs=8, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 500)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_embedding (Embedding)       (None, 500, 50)       250000      main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)             (None, 500, 50)       0           main_embedding[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "glove_embedding (Embedding)      (None, 500, 50)       250000      main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)               (None, 500, 64)       6464        dropout_27[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)               (None, 500, 64)       9664        dropout_27[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)               (None, 500, 64)       12864       dropout_27[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)               (None, 500, 64)       6464        glove_embedding[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)               (None, 500, 64)       9664        glove_embedding[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)               (None, 500, 64)       12864       glove_embedding[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D)  (None, 250, 64)       0           conv1d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D)  (None, 250, 64)       0           conv1d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D)  (None, 250, 64)       0           conv1d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D)  (None, 250, 64)       0           conv1d_37[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D)  (None, 250, 64)       0           conv1d_38[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D)  (None, 250, 64)       0           conv1d_39[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)             (None, 16000)         0           max_pooling1d_34[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)             (None, 16000)         0           max_pooling1d_35[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)             (None, 16000)         0           max_pooling1d_36[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)             (None, 16000)         0           max_pooling1d_37[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)             (None, 16000)         0           max_pooling1d_38[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)             (None, 16000)         0           max_pooling1d_39[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "concatenated_convs (Concatenate) (None, 96000)         0           flatten_34[0][0]                 \n",
      "                                                                   flatten_35[0][0]                 \n",
      "                                                                   flatten_36[0][0]                 \n",
      "                                                                   flatten_37[0][0]                 \n",
      "                                                                   flatten_38[0][0]                 \n",
      "                                                                   flatten_39[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "shortcut_main_embedding (Flatten (None, 25000)         0           dropout_27[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concat_main_embedding_plus_convs (None, 121000)        0           concatenated_convs[0][0]         \n",
      "                                                                   shortcut_main_embedding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)             (None, 121000)        0           concat_main_embedding_plus_convs[\n",
      "____________________________________________________________________________________________________\n",
      "dense_consolidator (Dense)       (None, 100)           12100100    dropout_28[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)             (None, 100)           0           dense_consolidator[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "final_output (Dense)             (None, 1)             101         dropout_29[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 12,658,185\n",
      "Trainable params: 12,408,185\n",
      "Non-trainable params: 250,000\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#fourth model combining our local embedding along with the glove embedding\n",
    "input_tensor = Input(shape=(500,), dtype='int32', name='main_input')\n",
    "\n",
    "embedding_layer = Embedding(5000, 50, input_length=500, name='main_embedding')(input_tensor)\n",
    "embedding_layer = Dropout(0.2)(embedding_layer)\n",
    "\n",
    "glove_embedding_layer = Embedding(5000, 50, input_length=500, name='glove_embedding', weights=[embedding_matrix], trainable=False)(input_tensor)\n",
    "\n",
    "convs = [] \n",
    "for num in range (2, 5): \n",
    "    x = Convolution1D(64, num, padding='same', activation=\"relu\")(embedding_layer)\n",
    "    x = MaxPooling1D()(x) \n",
    "    x = Flatten()(x) \n",
    "    convs.append(x)\n",
    "\n",
    "for num in range (2, 5): \n",
    "    x = Convolution1D(64, num, padding='same', activation=\"relu\")(glove_embedding_layer)\n",
    "    x = MaxPooling1D()(x) \n",
    "    x = Flatten()(x) \n",
    "    convs.append(x)\n",
    "\n",
    "conv_out = Concatenate(name='concatenated_convs')(convs)\n",
    "shortcut = Flatten(name='shortcut_main_embedding')(embedding_layer)\n",
    "dense_in = Concatenate(name='concat_main_embedding_plus_convs')([conv_out, shortcut])\n",
    "\n",
    "nex = Dropout(0.2)(dense_in)\n",
    "nex = Dense(100, activation=\"relu\", name='dense_consolidator')(nex)\n",
    "nex = Dropout(0.2)(nex)\n",
    "full_out = Dense (1, activation='sigmoid', name='final_output')(nex)\n",
    "\n",
    "combined_50_50_model = Model(input_tensor, full_out) \n",
    "combined_50_50_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_50_50_model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 17s - loss: 0.4411 - acc: 0.7729 - val_loss: 0.2913 - val_acc: 0.8785\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 17s - loss: 0.2114 - acc: 0.9179 - val_loss: 0.2703 - val_acc: 0.8878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0ae4592400>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_50_50_model.fit(trn, labels_train, validation_data=(test, labels_test), epochs=2, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/8\n",
      "25000/25000 [==============================] - 17s - loss: 0.1249 - acc: 0.9549 - val_loss: 0.3160 - val_acc: 0.8831\n",
      "Epoch 2/8\n",
      "25000/25000 [==============================] - 17s - loss: 0.0591 - acc: 0.9802 - val_loss: 0.4170 - val_acc: 0.8746\n",
      "Epoch 3/8\n",
      "25000/25000 [==============================] - 17s - loss: 0.0370 - acc: 0.9884 - val_loss: 0.4359 - val_acc: 0.8747\n",
      "Epoch 4/8\n",
      "25000/25000 [==============================] - 17s - loss: 0.0250 - acc: 0.9915 - val_loss: 0.5394 - val_acc: 0.8742\n",
      "Epoch 5/8\n",
      "25000/25000 [==============================] - 17s - loss: 0.0227 - acc: 0.9925 - val_loss: 0.5616 - val_acc: 0.8778\n",
      "Epoch 6/8\n",
      "25000/25000 [==============================] - 17s - loss: 0.0184 - acc: 0.9939 - val_loss: 0.6114 - val_acc: 0.8755\n",
      "Epoch 7/8\n",
      "25000/25000 [==============================] - 17s - loss: 0.0173 - acc: 0.9944 - val_loss: 0.6879 - val_acc: 0.8789\n",
      "Epoch 8/8\n",
      "25000/25000 [==============================] - 17s - loss: 0.0212 - acc: 0.9923 - val_loss: 0.6690 - val_acc: 0.8693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0ae42ebb00>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_50_50_model.fit(trn, labels_train, validation_data=(test, labels_test), epochs=8, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
